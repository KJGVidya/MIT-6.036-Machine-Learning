{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63e891eb",
   "metadata": {},
   "source": [
    "<h3><b>Perceptrons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cee18bf",
   "metadata": {},
   "source": [
    "Implement the perceptron algorithm, where\n",
    "\n",
    "-><b>data</b> is a numpy array of dimension d by n<br>\n",
    "-><b>labels</b> is numpy array of dimension 1 by n<br>\n",
    "-><b>params</b> is a dictionary specifying extra parameters to this algorithm; your algorithm should run a number of iterations equal to T<br>\n",
    "-><b>hook</b> is either None or a function that takes the tuple (th, th0) as an argument and displays the separator graphically. We won't be testing this in the Tutor, but it will help you in debugging on your own machine.<br>\n",
    "\n",
    "It should return a tuple of θ (a d by 1 array) and θ<sub>0</sub>  (a 1 by 1 array).\n",
    "\n",
    "We have given you some data sets in the code file for you to test your implementation.\n",
    "\n",
    "Your function should initialize all parameters to 0, then run through the data, in the order it is given, performing an update to the parameters whenever the current parameters would make a mistake on that data point. Perform T iterations through the data. After every parameter update, if hook is defined, call it on the current (th, th0) (as a single parameter in a python tuple).\n",
    "\n",
    "When debugging on your own, you can use the procedure test_linear_classifier for testing. By default, it pauses after every parameter update to show the separator. For data sets not in 2D, or just to get the answer, set draw = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e66f4808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def perceptron(data, labels, params={}, hook=None):\n",
    "    # if T not in params, default to 100\n",
    "    T = params.get('T', 100)\n",
    "\n",
    "    # Your implementation here\n",
    "    th=np.zeros([data.shape[0],1])\n",
    "    th0=np.array([[0]])\n",
    "    n=len(data)**2\n",
    "    for j in range(1,T):   \n",
    "        for i in range(data.shape[1]):\n",
    "           if labels.T[i]*(th.T.dot(data.T[i])+th0)<=0:\n",
    "               th=np.array(th.T+labels.T[[i]]*data.T[[i]],dtype = np.float64).T\n",
    "               th0=np.array(th0+labels.T[i],dtype = np.float64)\n",
    "               t=[np.array(th).tolist(),np.array(th0).tolist()]\n",
    "               #print(t)\n",
    "    return th,th0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05457c5",
   "metadata": {},
   "source": [
    "### Implement averaged perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43b2e0b",
   "metadata": {},
   "source": [
    "Regular perceptron can be somewhat sensitive to the most recent examples that it sees. Instead, averaged perceptron produces a more stable output by outputting the average value of th and th0 across all iterations.\n",
    "\n",
    "Implement averaged perceptron with the same spec as regular perceptron, and using the pseudocode below as a guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b56cc7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def averaged_perceptron(data, labels, params={}, hook=None):\n",
    "    # if T not in params, default to 100\n",
    "    T = params.get('T', 100)\n",
    "\n",
    "    # Your implementation here\n",
    "    (d,n)=data.shape\n",
    "    th=np.zeros([d,1])\n",
    "    th0=np.array([[0]])\n",
    "    ths=np.zeros([d,1])\n",
    "    th0s=np.array([[0]])\n",
    "    for j in range(0,T):   \n",
    "        for i in range(n):\n",
    "            if labels.T[i]*(th.T.dot(data.T[i])+th0)<=0:\n",
    "               th=np.array(th.T+labels.T[[i]]*data.T[[i]]).T\n",
    "               th0=np.array(th0+labels.T[i])\n",
    "               #t=[np.array(th).tolist(),np.array(th0).tolist()]\n",
    "            ths=ths+th\n",
    "            th0s=th0s+th0\n",
    "               \n",
    "    return ths/(n*T),th0s/(n*T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972ed142",
   "metadata": {},
   "source": [
    "### Evaluating a learning algorithm using a data source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8554c4ae",
   "metadata": {},
   "source": [
    "Construct a testing procedure that takes a learning algorithm and a data source as input and runs the learning algorithm multiple times, each time evaluating the resulting classifier as above. It should report the overall average classification accuracy.\n",
    "\n",
    "You can use our implementation of eval_classifier as above.\n",
    "\n",
    "Write the function eval_learning_alg that takes:\n",
    "\n",
    "<b>learner</b> - a function, such as perceptron or averaged_perceptron<br>\n",
    "<b>data_gen</b>- a data generator, call it with a desired data set size; returns a tuple (data, labels)<br>\n",
    "<b>n_train</b> - the size of the learning sets<br>\n",
    "<b>n_test</b> - the size of the test sets<br>\n",
    "<b>it</b> - the number of iterations to average over<br>\n",
    "and returns the average classification accuracy as a float between 0. and 1..\n",
    "\n",
    "Note: Be sure to generate your training data and then testing data in that order, to ensure that the pseudorandomly generated data matches that in the test code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8763a990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_learning_alg(learner, data_gen, n_train, n_test, it):\n",
    "    e=0\n",
    "    for i in range (0, it):\n",
    "        data_train,labels_train=data_gen(n_train)\n",
    "        data_test,labels_test=data_gen(n_test)\n",
    "        e=e+eval_classifier(learner, data_train, labels_train, data_test, labels_test)\n",
    "    return e/it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6436e12c",
   "metadata": {},
   "source": [
    "### Evaluating a learning algorithm with a fixed dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0244d408",
   "metadata": {},
   "source": [
    "Cross-validation is a strategy for evaluating a learning algorithm, using a single training set of size \n",
    "n. Cross-validation takes in a learning algorithm L, a fixed data set D, and a parameter k. It will run the learning algorithm k different times, then evaluate the accuracy of the resulting classifier, and ultimately return the average of the accuracies over each of the k \"runs\" of L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e70bf4",
   "metadata": {},
   "source": [
    "So, each time, it trains on k−1 of the pieces of the data set and tests the resulting hypothesis on the piece that was not used for training.\n",
    "\n",
    "When k=n, it is called leave-one-out cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a4a5f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xval_learning_alg(learner, data, labels, k):\n",
    "    # cross validation of learning algorithm\n",
    "    e=0\n",
    "    data_split=np.array(np.array_split(data,k,axis=1)) \n",
    "    labels_split=np.array(np.array_split(labels,k,axis=1))\n",
    "    for i in range(k):\n",
    "        test_data=data_split[i]\n",
    "        test_labels=labels_split[i]\n",
    "        a=[*range(k)]\n",
    "        a.pop(i)\n",
    "        train_data=np.concatenate(data_split[a],axis=1)\n",
    "        train_labels=np.concatenate(labels_split[a],axis=1)\n",
    "        #print(test_data)\n",
    "        e=e+eval_classifier(learner,train_data,train_labels,test_data,test_labels)\n",
    "    return e/k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f0c412",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d348ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
